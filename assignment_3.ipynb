{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fcc77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from scipy.spatial import distance, distance_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c64aada-ca6d-4fac-9c50-ff27f17c909c",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f75e582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145749, 77)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTemporary dataset for testing purposes. 2 features, 7 clusters\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# KDD Dataset\n",
    "# First column is the BLOCK ID (class label), BLOCK IDs are integers running from 1 to 303 with 153 unique values (k)\n",
    "# Second column is the ELEMENT ID (sample number), unique numbers, not ordered\n",
    "# Third column is the class of the example. Homologous proteins = 1, non-homologous proteins = 0\n",
    "data = pd.read_csv('bio_train.csv',skiprows=0).to_numpy(dtype='object')\n",
    "\n",
    "\n",
    "#####################\n",
    "# Toy Dataset\n",
    "#dataset = np.genfromtxt('dataset1_noCluster7.csv', delimiter = ',')[1:]\n",
    "#dataset_ft = dataset[:,:2]\n",
    "#dataset_lb = dataset[:,-1]\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#dataset_ft = scaler.fit_transform(dataset_ft)\n",
    "\n",
    "#plt.scatter(dataset_ft[:,0], dataset_ft[:,1], c = dataset_lb)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3dee64-6fe3-4525-8975-94db19e8025a",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3734f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle, split into labels/features and normalize data\n",
    "def process_data(data):\n",
    "    # Shuffle\n",
    "    shuffle = np.random.permutation(len(data))\n",
    "    data = data[shuffle]\n",
    "    \n",
    "    # Split\n",
    "    block_ids = data[:,0]\n",
    "    element_ids = data[:,1]\n",
    "    homology = data[:,2]\n",
    "    features = data[:,3:]\n",
    "    \n",
    "    # Normalize the features\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "    \n",
    "    return block_ids, element_ids, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be3c79a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "block_ids, element_ids, features = process_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb4af20-7dd3-405a-89f7-ecfd3c799188",
   "metadata": {},
   "source": [
    "### Task 1 - Lloyds Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee23b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lloyds(data, k=153):\n",
    "    # Number of samples and features of the dataset\n",
    "    \n",
    "    n_samples, n_features = np.shape(data)\n",
    "    \n",
    "    # Pick k random points from data to be the initial cluster centers (eventually use kmeans+ here?)\n",
    "    rand_nums = np.random.randint(0,n_samples,k)\n",
    "    cluster_means = data[rand_nums]\n",
    "    \n",
    "    old_means = np.zeros([k, n_features])\n",
    "    counter = 0\n",
    "    \n",
    "    while (old_means != cluster_means).any():\n",
    "    \n",
    "        counter += 1\n",
    "        print(\"iteration: \",counter)\n",
    "        old_means = np.copy(cluster_means)\n",
    "        \n",
    "        # measure assingment runtime\n",
    "        start_assign = time.perf_counter()\n",
    "        \n",
    "        ############# Assign step\n",
    "        # first approach\n",
    "        dist_matrix = distance_matrix(data, cluster_means)\n",
    "        cluster_labels = np.argmin(dist_matrix, axis=1)\n",
    "        \n",
    "        \n",
    "        # second approach for computing the distances\n",
    "        #cluster_labels = np.zeros(n_samples)\n",
    "        #sample_dist = np.zeros(k)\n",
    "        #for i in range(n):\n",
    "        #    for j in range(k):\n",
    "        #        sample_dist[j] = distance.sqeuclidean(data[i], cluster_means[j])\n",
    "        #    cluster_labels[i] = np.argmin(sample_dist)\n",
    "        \n",
    "        # measure update runtime\n",
    "        start_update = time.perf_counter()\n",
    "        \n",
    "        ############# Update step\n",
    "        for j in range(k):\n",
    "            point_sum = np.zeros(n_features)\n",
    "            point_nr = 0\n",
    "            for i in range(n_samples):\n",
    "                if cluster_labels[i] == j:\n",
    "                    point_nr += 1\n",
    "                    point_sum += data[i]\n",
    "            \n",
    "            if point_nr == 0:\n",
    "                cluster_means[j] = np.copy(old_means[j])\n",
    "            else:\n",
    "                cluster_means[j] = point_sum/point_nr\n",
    "            \n",
    "        end_update = time.perf_counter()\n",
    "        \n",
    "        print('Assign step runtime: '+str(start_update - start_assign))\n",
    "        print('Update step  runtime: '+str(end_update - start_update))\n",
    "        \n",
    "    print('KMeans converged in '+str(counter)+' iterations.')\n",
    "    return cluster_labels, cluster_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1b6ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  1\n",
      "Assign step runtime: 11.218267659000048\n",
      "Update step  runtime: 4.288877942999989\n",
      "iteration:  2\n",
      "Assign step runtime: 11.547677550999992\n",
      "Update step  runtime: 4.280310646000089\n",
      "iteration:  3\n",
      "Assign step runtime: 11.186793286000011\n",
      "Update step  runtime: 4.115879010999947\n",
      "iteration:  4\n",
      "Assign step runtime: 11.068957857999976\n",
      "Update step  runtime: 4.2998429700001\n",
      "iteration:  5\n",
      "Assign step runtime: 12.28592508600002\n",
      "Update step  runtime: 4.481656117000057\n",
      "iteration:  6\n",
      "Assign step runtime: 11.803110372999981\n",
      "Update step  runtime: 4.224168856999995\n",
      "iteration:  7\n",
      "Assign step runtime: 12.193432981\n",
      "Update step  runtime: 4.249796253999989\n",
      "iteration:  8\n",
      "Assign step runtime: 11.72605226099995\n",
      "Update step  runtime: 4.247098960000017\n",
      "iteration:  9\n",
      "Assign step runtime: 11.651492904999941\n",
      "Update step  runtime: 4.233769107000057\n",
      "iteration:  10\n",
      "Assign step runtime: 11.651313229000039\n",
      "Update step  runtime: 4.302390816999946\n",
      "iteration:  11\n",
      "Assign step runtime: 11.801234926000006\n",
      "Update step  runtime: 4.203737339999975\n",
      "iteration:  12\n",
      "Assign step runtime: 11.671166842999924\n",
      "Update step  runtime: 4.224264104000099\n",
      "iteration:  13\n",
      "Assign step runtime: 11.643728396000029\n",
      "Update step  runtime: 4.431557644999998\n",
      "iteration:  14\n",
      "Assign step runtime: 11.915688642000077\n",
      "Update step  runtime: 4.1838904699999375\n",
      "iteration:  15\n",
      "Assign step runtime: 11.479549794000036\n",
      "Update step  runtime: 4.499553994999928\n",
      "iteration:  16\n",
      "Assign step runtime: 11.69209082000009\n",
      "Update step  runtime: 4.353437375999988\n",
      "iteration:  17\n",
      "Assign step runtime: 11.860188077999965\n",
      "Update step  runtime: 4.4809876100000565\n",
      "iteration:  18\n",
      "Assign step runtime: 11.971801040999935\n",
      "Update step  runtime: 4.00071451000008\n",
      "iteration:  19\n",
      "Assign step runtime: 11.565352053999959\n",
      "Update step  runtime: 4.183857498000066\n",
      "iteration:  20\n",
      "Assign step runtime: 12.377103290000036\n",
      "Update step  runtime: 4.4165198939999755\n",
      "iteration:  21\n",
      "Assign step runtime: 12.009699386999955\n",
      "Update step  runtime: 4.475716171000045\n",
      "iteration:  22\n",
      "Assign step runtime: 12.189300351000043\n",
      "Update step  runtime: 4.113177279999945\n",
      "iteration:  23\n",
      "Assign step runtime: 11.235852580000028\n",
      "Update step  runtime: 4.128839790000029\n",
      "iteration:  24\n",
      "Assign step runtime: 10.92162113400002\n",
      "Update step  runtime: 4.055576936999955\n",
      "iteration:  25\n",
      "Assign step runtime: 11.37862292200009\n",
      "Update step  runtime: 3.9351883269999917\n",
      "iteration:  26\n",
      "Assign step runtime: 10.980890669000019\n",
      "Update step  runtime: 3.9191477079999686\n",
      "iteration:  27\n",
      "Assign step runtime: 11.114838216999942\n",
      "Update step  runtime: 4.137829936999992\n",
      "iteration:  28\n",
      "Assign step runtime: 11.18421578799996\n",
      "Update step  runtime: 4.099715162000052\n",
      "iteration:  29\n",
      "Assign step runtime: 11.048881778999998\n",
      "Update step  runtime: 4.202436597000087\n",
      "iteration:  30\n",
      "Assign step runtime: 11.745725929000173\n",
      "Update step  runtime: 4.187192317999916\n",
      "iteration:  31\n",
      "Assign step runtime: 11.645273540999824\n",
      "Update step  runtime: 4.394596667000087\n",
      "iteration:  32\n",
      "Assign step runtime: 11.310596729000054\n",
      "Update step  runtime: 3.7632408429999487\n",
      "iteration:  33\n",
      "Assign step runtime: 11.437403199000073\n",
      "Update step  runtime: 4.087642370999902\n",
      "iteration:  34\n",
      "Assign step runtime: 12.113633568000068\n",
      "Update step  runtime: 4.256666093999911\n",
      "iteration:  35\n",
      "Assign step runtime: 11.907420837000018\n",
      "Update step  runtime: 4.235857977000023\n",
      "iteration:  36\n",
      "Assign step runtime: 11.432428548999951\n",
      "Update step  runtime: 3.9634139810000306\n",
      "iteration:  37\n",
      "Assign step runtime: 11.433219029999918\n",
      "Update step  runtime: 4.3403289840000525\n",
      "iteration:  38\n",
      "Assign step runtime: 11.779985282000098\n",
      "Update step  runtime: 4.20493114299984\n",
      "iteration:  39\n",
      "Assign step runtime: 12.090282435999825\n",
      "Update step  runtime: 4.216614072000084\n",
      "iteration:  40\n",
      "Assign step runtime: 11.862355821999927\n",
      "Update step  runtime: 4.74438476499995\n",
      "iteration:  41\n",
      "Assign step runtime: 11.697140004000175\n",
      "Update step  runtime: 4.555299320999893\n",
      "iteration:  42\n",
      "Assign step runtime: 12.889260373999832\n",
      "Update step  runtime: 4.204379718000155\n",
      "iteration:  43\n",
      "Assign step runtime: 11.409951532999912\n",
      "Update step  runtime: 4.670225939000147\n",
      "iteration:  44\n",
      "Assign step runtime: 11.94541631800007\n",
      "Update step  runtime: 3.9813785199999074\n",
      "iteration:  45\n",
      "Assign step runtime: 11.070119771999998\n",
      "Update step  runtime: 4.223585109999931\n",
      "iteration:  46\n",
      "Assign step runtime: 11.916150722999873\n",
      "Update step  runtime: 4.071728201000042\n",
      "iteration:  47\n",
      "Assign step runtime: 11.223585085999957\n",
      "Update step  runtime: 4.2401993949999905\n",
      "iteration:  48\n",
      "Assign step runtime: 12.279040356999985\n",
      "Update step  runtime: 4.241024928999877\n",
      "iteration:  49\n",
      "Assign step runtime: 12.102478531000088\n",
      "Update step  runtime: 4.259225139999899\n",
      "iteration:  50\n",
      "Assign step runtime: 11.624147410999967\n",
      "Update step  runtime: 4.260250303000021\n",
      "iteration:  51\n",
      "Assign step runtime: 12.093648796000025\n",
      "Update step  runtime: 4.259730445000059\n",
      "iteration:  52\n",
      "Assign step runtime: 11.607241852000016\n",
      "Update step  runtime: 4.251120115000049\n",
      "iteration:  53\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g4/q80fmvg52738ggk6c7xks8t40000gn/T/ipykernel_5923/2134237175.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloyds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#labels, centers = loyds(dataset_ft, 7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/g4/q80fmvg52738ggk6c7xks8t40000gn/T/ipykernel_5923/2848409379.py\u001b[0m in \u001b[0;36mloyds\u001b[0;34m(data, k)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m############# Assign step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# first approach\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mdist_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mcluster_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/datascience1/lib/python3.8/site-packages/scipy/spatial/_kdtree.py\u001b[0m in \u001b[0;36mdistance_matrix\u001b[0;34m(x, y, p, threshold)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminkowski_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/datascience1/lib/python3.8/site-packages/scipy/spatial/_kdtree.py\u001b[0m in \u001b[0;36mminkowski_distance\u001b[0;34m(x, y, p)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mminkowski_distance_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mminkowski_distance_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/datascience1/lib/python3.8/site-packages/scipy/spatial/_kdtree.py\u001b[0m in \u001b[0;36mminkowski_distance_p\u001b[0;34m(x, y, p)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labels, centers = lloyds(features)\n",
    "#labels, centers = lloyds(dataset_ft, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b5ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(dataset_ft[:,0], dataset_ft[:,1], c = labels)\n",
    "#plt.scatter(centers[:,0], centers[:,1], c='r')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e6240eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "NMI_score = normalized_mutual_info_score(block_ids, labels)\n",
    "print(NMI_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f202e35d-2956-4ef8-9832-307a0ef484cb",
   "metadata": {},
   "source": [
    "### Task 2 - LSH + Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "361dddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function defines a hash function according to the notes on LSH + Kmeans and assigns \n",
    "# the samples to the buckets.\n",
    "# There is still a mistake in this function\n",
    "\n",
    "def hash_simple(data, no_buckets):\n",
    "    \n",
    "    no_samples = len(data)\n",
    "    \n",
    "    hash_values = np.zeros(no_samples)\n",
    "    \n",
    "    vector_p = np.random.normal(loc=0.0, scale=1.0, size=len(data[0]))\n",
    "    \n",
    "    for i in range(n):\n",
    "        hash_values[i] = data[i].dot(vector_p)\n",
    "        \n",
    "    min_val = np.min(hash_values)\n",
    "    max_val = np.max(hash_values)\n",
    "    \n",
    "    bucket_size = (max_val-min_val) / (no_buckets-1)\n",
    "    \n",
    "    return np.floor(hash_values/bucket_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
