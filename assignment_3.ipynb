{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fcc77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from scipy.spatial import distance, distance_matrix\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c64aada-ca6d-4fac-9c50-ff27f17c909c",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f75e582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# KDD Dataset\n",
    "# First column is the BLOCK ID (class label), BLOCK IDs are integers running from 1 to 303 with 153 unique values (k)\n",
    "# Second column is the ELEMENT ID (sample number), unique numbers, not ordered\n",
    "# Third column is the class of the example. Homologous proteins = 1, non-homologous proteins = 0\n",
    "data = pd.read_csv('bio_train.csv',skiprows=0).to_numpy(dtype='object')\n",
    "\n",
    "\n",
    "#####################\n",
    "# Toy Dataset\n",
    "#dataset = np.genfromtxt('dataset1_noCluster7.csv', delimiter = ',')[1:]\n",
    "#dataset_ft = dataset[:,:2]\n",
    "#dataset_lb = dataset[:,-1]\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#dataset_ft = scaler.fit_transform(dataset_ft)\n",
    "\n",
    "#plt.scatter(dataset_ft[:,0], dataset_ft[:,1], c = dataset_lb)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3dee64-6fe3-4525-8975-94db19e8025a",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3734f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle, split into labels/features and normalize data\n",
    "def process_data(data):\n",
    "    # Shuffle\n",
    "    shuffle = np.random.permutation(len(data))\n",
    "    data = data[shuffle]\n",
    "    \n",
    "    # Split\n",
    "    block_ids = data[:,0]\n",
    "    element_ids = data[:,1]\n",
    "    homology = data[:,2]\n",
    "    features = data[:,3:]\n",
    "    \n",
    "    # Normalize the features\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "    \n",
    "    return block_ids, element_ids, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be3c79a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "block_ids, element_ids, features = process_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb4af20-7dd3-405a-89f7-ecfd3c799188",
   "metadata": {},
   "source": [
    "### Task 1 - Lloyds Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee23b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lloyds(data, k=153):\n",
    "    # Number of samples and features of the dataset\n",
    "    \n",
    "    n_samples, n_features = np.shape(data)\n",
    "    \n",
    "    # Pick k random points from data to be the initial cluster centers (eventually use kmeans+ here?)\n",
    "    rand_nums = np.random.randint(0,n_samples,k)\n",
    "    cluster_means = data[rand_nums]\n",
    "    \n",
    "    old_means = np.zeros([k, n_features])\n",
    "    counter = 0\n",
    "    \n",
    "    while (old_means != cluster_means).any():\n",
    "    \n",
    "        counter += 1\n",
    "        if counter == 200:\n",
    "            break\n",
    "        print(\"iteration: \",counter)\n",
    "        old_means = np.copy(cluster_means)\n",
    "        \n",
    "        # measure assingment runtime\n",
    "        #start_assign = time.perf_counter()\n",
    "        \n",
    "        ############# Assign step\n",
    "        # first approach\n",
    "        distance_matrix = cdist(data, cluster_means, metric='sqeuclidean')\n",
    "        \n",
    "        #distance_matrix = distance_matrix(data, cluster_means)\n",
    "        cluster_labels = np.argmin(distance_matrix, axis=1)\n",
    "        \n",
    "        ############# Update step\n",
    "        for j in range(k):\n",
    "            \n",
    "            idcs = np.where(cluster_labels == j)[0]\n",
    "            cluster_size = len(idcs)\n",
    "            \n",
    "            if cluster_size == 0:\n",
    "                cluster_means[j] = np.copy(old_means[j])\n",
    "            else:\n",
    "                cluster_sum = np.sum(data[idcs], axis=0)\n",
    "                cluster_means[j] = cluster_sum/cluster_size\n",
    "            \n",
    "            \n",
    "           \n",
    "            \n",
    "        #end_update = time.perf_counter()\n",
    "        \n",
    "        #print('Assign step runtime: '+str(start_update - start_assign))\n",
    "        #print('Update step runtime: '+str(end_update - start_update))\n",
    "        \n",
    "    print('KMeans converged in '+str(counter)+' iterations.')\n",
    "    return cluster_labels, cluster_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1b6ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  1\n",
      "iteration:  2\n",
      "iteration:  3\n",
      "iteration:  4\n",
      "iteration:  5\n",
      "iteration:  6\n",
      "iteration:  7\n",
      "iteration:  8\n",
      "iteration:  9\n",
      "iteration:  10\n",
      "iteration:  11\n",
      "iteration:  12\n",
      "iteration:  13\n",
      "iteration:  14\n",
      "iteration:  15\n",
      "iteration:  16\n",
      "iteration:  17\n",
      "iteration:  18\n",
      "iteration:  19\n",
      "iteration:  20\n",
      "iteration:  21\n",
      "iteration:  22\n",
      "iteration:  23\n",
      "iteration:  24\n",
      "iteration:  25\n",
      "iteration:  26\n",
      "iteration:  27\n",
      "iteration:  28\n",
      "iteration:  29\n",
      "iteration:  30\n",
      "iteration:  31\n",
      "iteration:  32\n",
      "iteration:  33\n",
      "iteration:  34\n",
      "iteration:  35\n",
      "iteration:  36\n",
      "iteration:  37\n",
      "iteration:  38\n",
      "iteration:  39\n",
      "iteration:  40\n",
      "iteration:  41\n",
      "iteration:  42\n",
      "iteration:  43\n",
      "iteration:  44\n",
      "iteration:  45\n",
      "iteration:  46\n",
      "iteration:  47\n",
      "iteration:  48\n",
      "iteration:  49\n",
      "iteration:  50\n",
      "iteration:  51\n",
      "iteration:  52\n",
      "iteration:  53\n",
      "iteration:  54\n",
      "iteration:  55\n",
      "iteration:  56\n",
      "iteration:  57\n",
      "iteration:  58\n",
      "iteration:  59\n",
      "iteration:  60\n",
      "iteration:  61\n",
      "iteration:  62\n",
      "iteration:  63\n",
      "iteration:  64\n",
      "iteration:  65\n",
      "iteration:  66\n",
      "iteration:  67\n",
      "iteration:  68\n",
      "iteration:  69\n",
      "iteration:  70\n",
      "iteration:  71\n",
      "iteration:  72\n",
      "iteration:  73\n",
      "iteration:  74\n",
      "iteration:  75\n",
      "iteration:  76\n",
      "iteration:  77\n",
      "iteration:  78\n",
      "iteration:  79\n",
      "iteration:  80\n",
      "iteration:  81\n",
      "iteration:  82\n",
      "iteration:  83\n",
      "iteration:  84\n",
      "iteration:  85\n",
      "iteration:  86\n",
      "iteration:  87\n",
      "iteration:  88\n",
      "iteration:  89\n",
      "iteration:  90\n",
      "iteration:  91\n",
      "iteration:  92\n",
      "iteration:  93\n",
      "iteration:  94\n",
      "iteration:  95\n",
      "iteration:  96\n",
      "iteration:  97\n",
      "iteration:  98\n",
      "iteration:  99\n",
      "iteration:  100\n",
      "iteration:  101\n",
      "iteration:  102\n",
      "iteration:  103\n",
      "iteration:  104\n",
      "iteration:  105\n",
      "iteration:  106\n",
      "iteration:  107\n",
      "iteration:  108\n",
      "iteration:  109\n",
      "iteration:  110\n",
      "iteration:  111\n",
      "iteration:  112\n",
      "iteration:  113\n",
      "iteration:  114\n",
      "iteration:  115\n",
      "iteration:  116\n",
      "iteration:  117\n",
      "iteration:  118\n",
      "iteration:  119\n",
      "iteration:  120\n",
      "iteration:  121\n",
      "iteration:  122\n",
      "iteration:  123\n",
      "iteration:  124\n",
      "iteration:  125\n",
      "iteration:  126\n",
      "iteration:  127\n",
      "iteration:  128\n",
      "iteration:  129\n",
      "iteration:  130\n",
      "iteration:  131\n",
      "iteration:  132\n",
      "iteration:  133\n",
      "iteration:  134\n",
      "iteration:  135\n",
      "iteration:  136\n",
      "iteration:  137\n",
      "iteration:  138\n",
      "iteration:  139\n",
      "iteration:  140\n",
      "iteration:  141\n",
      "iteration:  142\n",
      "iteration:  143\n",
      "iteration:  144\n",
      "iteration:  145\n",
      "iteration:  146\n",
      "iteration:  147\n",
      "iteration:  148\n",
      "iteration:  149\n",
      "iteration:  150\n",
      "iteration:  151\n",
      "iteration:  152\n",
      "iteration:  153\n",
      "iteration:  154\n",
      "iteration:  155\n",
      "iteration:  156\n",
      "iteration:  157\n",
      "iteration:  158\n",
      "iteration:  159\n",
      "iteration:  160\n",
      "iteration:  161\n",
      "iteration:  162\n",
      "iteration:  163\n",
      "iteration:  164\n",
      "iteration:  165\n",
      "iteration:  166\n",
      "iteration:  167\n",
      "iteration:  168\n",
      "iteration:  169\n",
      "iteration:  170\n",
      "iteration:  171\n",
      "iteration:  172\n",
      "iteration:  173\n",
      "iteration:  174\n",
      "iteration:  175\n",
      "iteration:  176\n",
      "iteration:  177\n",
      "iteration:  178\n",
      "iteration:  179\n",
      "iteration:  180\n",
      "iteration:  181\n",
      "iteration:  182\n",
      "iteration:  183\n",
      "iteration:  184\n",
      "iteration:  185\n",
      "iteration:  186\n",
      "iteration:  187\n",
      "iteration:  188\n",
      "iteration:  189\n",
      "iteration:  190\n",
      "iteration:  191\n",
      "iteration:  192\n",
      "iteration:  193\n",
      "iteration:  194\n",
      "iteration:  195\n",
      "iteration:  196\n",
      "iteration:  197\n",
      "iteration:  198\n",
      "iteration:  199\n",
      "KMeans converged in 200 iterations.\n"
     ]
    }
   ],
   "source": [
    "labels, centers = lloyds(features)\n",
    "#labels, centers = lloyds(dataset_ft, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b5ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(dataset_ft[:,0], dataset_ft[:,1], c = labels)\n",
    "#plt.scatter(centers[:,0], centers[:,1], c='r')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e6240eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1916718931784005\n"
     ]
    }
   ],
   "source": [
    "NMI_score = normalized_mutual_info_score(block_ids, labels)\n",
    "print(NMI_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f202e35d-2956-4ef8-9832-307a0ef484cb",
   "metadata": {},
   "source": [
    "### Task 2 - LSH + Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "361dddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function defines a hash function according to the notes on LSH + Kmeans and assigns \n",
    "# the samples to the buckets.\n",
    "# There is still a mistake in this function\n",
    "\n",
    "def hash_simple(data, no_buckets):\n",
    "    \n",
    "    no_samples = len(data)\n",
    "    \n",
    "    hash_values = np.zeros(no_samples)\n",
    "    \n",
    "    vector_p = np.random.normal(loc=0.0, scale=1.0, size=len(data[0]))\n",
    "    \n",
    "    for i in range(n):\n",
    "        hash_values[i] = data[i].dot(vector_p)\n",
    "        \n",
    "    min_val = np.min(hash_values)\n",
    "    max_val = np.max(hash_values)\n",
    "    \n",
    "    bucket_size = (max_val-min_val) / (no_buckets-1)\n",
    "    \n",
    "    return np.floor(hash_values/bucket_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8de36888-1f1d-4f22-ae65-fa3e6694cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class defines a given number of hash functions. \n",
    "# The calculate_hash_values function can be used to calclueate the hash values of any array with no_features as the second dimension\n",
    "class hash_functions:\n",
    "    def __init__(self, no_functions, w, no_features):\n",
    "        self.w = w #scalar\n",
    "        self.b = np.zeros(no_functions) # vector\n",
    "        self.a = np.random.normal(loc=0.0, scale=1.0, size=(no_functions, no_features)) # matrix\n",
    "\n",
    "    def calculate_hash_values(self,data):\n",
    "        hash_values = (np.dot(data, self.a.T) + self.b) / self.w\n",
    "        return hash_values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "021e5e1b-dd4f-4055-b96c-a4e59902883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define hash functions\n",
    "no_features = len(features[0])\n",
    "w=3\n",
    "hash_funcs = hash_functions(16, w, no_features)\n",
    "\n",
    "#calculate the 16 hash values from all features\n",
    "hash_values = hash_funcs.calculate_hash_values(features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62769480-a15a-46fc-a4e7-bfa80682f667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
